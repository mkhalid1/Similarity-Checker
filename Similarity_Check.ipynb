{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def clean_text(txt):\n",
    "    \"\"\"Cleans a string of text removing punctuation\n",
    "    \"\"\"\n",
    "    txt = txt.lower()\n",
    "    txt = txt.replace('.','')\n",
    "    txt = txt.replace(',','')\n",
    "    txt = txt.replace('!','')\n",
    "    txt = txt.replace('?','')\n",
    "    txt = txt.replace('-','')\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    \"\"\"Computes word Stems, and returns a dictionary\n",
    "    \"\"\"\n",
    "    two_suff = ['ed','ty','or','fy', 'er'] #Suffix of len 2\n",
    "    three_suff = ['ful','ant','ion','ily']\n",
    "    four_suff = ['ship','ward','ular','ment', 'less']\n",
    "    if word[-3:] == 'ing':\n",
    "        if len(word) > 6  and word[-4] == word[-5] :\n",
    "            word = word[:-4]\n",
    "        else:\n",
    "            word = word[:-3]\n",
    "    elif word[-2:] == 'er' or word[-2:] == 'ly' or word[-2:] in two_suff:\n",
    "        word = word[:-2]\n",
    "    elif len(word) > 2 and word[-1] == 's':\n",
    "        word = stem(word[:-1])\n",
    "    elif word[-4:] == 'able'or word[-4:] in four_suff:\n",
    "        word = word[:-4]\n",
    "    elif word[-3:] == 'ous' or word[-3:] in three_suff:\n",
    "        word = word[:-3]\n",
    "        \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_sen(s):\n",
    "    \"\"\"Computes a dictionary of sentence lenghts\n",
    "    \"\"\"\n",
    "    words = s.replace('.', '##')\n",
    "    words = words.replace('!', '##')\n",
    "    words = words.replace('?', '##')\n",
    "    words = words.split('##')\n",
    "    len_dic = {}\n",
    "    #print(words)\n",
    "    result = []\n",
    "    for i in range(len(words)):\n",
    "        wordz = words[i].split()\n",
    "        result += [len(wordz)]\n",
    "    #print(result)\n",
    "    for next_sen in result:\n",
    "        if next_sen not in len_dic:\n",
    "            len_dic[next_sen] = 1\n",
    "        else:\n",
    "            len_dic[next_sen] += 1\n",
    "    return len_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dictionaries(d1, d2):\n",
    "    \"\"\"Compares two dictionaries\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    total = 0\n",
    "    for key in d1:\n",
    "        total += d1[key]\n",
    "    \n",
    "    \n",
    "    for key in d1:\n",
    "        try:\n",
    "            if key in d2:\n",
    "                score += math.log(d1[key]/total)\n",
    "            else:\n",
    "                score += math.log(0.5/total)\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punc_dic(s):\n",
    "    \"\"\"Returns a list of the punctuation used in the text sample,\n",
    "       with duplicates\n",
    "    \"\"\"\n",
    "    result = ''\n",
    "    for i in range(len(s)):\n",
    "        if s[i] in '.!?:;':\n",
    "            result += s[i] + ' '\n",
    "    words = result.split()\n",
    "    dic = {}\n",
    "    \n",
    "    for next_word in words: #makes the self.punc dictionary\n",
    "        if next_word not in dic:\n",
    "            dic[next_word] = 1\n",
    "        else:\n",
    "            dic[next_word] += 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextModel:\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        \"\"\"Constructer \n",
    "        \"\"\"\n",
    "        self.name = model_name # name of the text model\n",
    "        self.words = {} # dictionary of no.of times word appears\n",
    "        self.word_lengths = {} # dictionary of lenghts\n",
    "        self.stems = {} #a dictionary number of times each word stem appears\n",
    "        self.sentence_lengths = {} #no. of times each sentence legth appears\n",
    "        self.punc = {} #no. of times punctuation used\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Return a string representation of the TextModel.\"\"\"\n",
    "        s = 'text model name: ' + self.name + '\\n'\n",
    "        s += '  number of words: ' + str(len(self.words)) + '\\n'\n",
    "        s += '  number of word lengths: ' + str(len(self.word_lengths))\n",
    "        s += '\\n'\n",
    "        s += '  number of word stems: ' + str(len(self.stems))\n",
    "        s += '\\n'\n",
    "        s += '  number of sentence lengths: ' + str(len(self.sentence_lengths))\n",
    "        s += '\\n'\n",
    "        s += '  number of punctuation types: ' + str(len(self.punc))\n",
    "        return s\n",
    "\n",
    "    def add_string(self, s):\n",
    "        \"\"\"Adds a string to the Text Model\n",
    "        \"\"\"\n",
    "        words = s.lower()\n",
    "        words = words.split()\n",
    "        \n",
    "        for next_word in words: #makes the self.stems dictionary\n",
    "            word_stem = stem(next_word)\n",
    "            if word_stem not in self.stems:\n",
    "                self.stems[word_stem] = 1\n",
    "            else:\n",
    "                self.stems[word_stem] += 1\n",
    "\n",
    "        self.sentence_lengths = len_sen(s) # makes senLen dic\n",
    "\n",
    "\n",
    "\n",
    "        self.punc = punc_dic(s) #outsorce the problem to punc_dic\n",
    "        words = clean_text(s)\n",
    "        words = words.split()\n",
    "        #print(words)\n",
    "        current_word = words[0]\n",
    "        \n",
    "        for next_word in words:\n",
    "            len_word = len(next_word)\n",
    "            if len_word not in self.word_lengths:\n",
    "                self.word_lengths[len_word] = 1\n",
    "            else:\n",
    "                self.word_lengths[len_word] += 1\n",
    "            if next_word not in self.words:\n",
    "                self.words[next_word] = 1\n",
    "            else:\n",
    "                self.words[next_word] += 1\n",
    "                \n",
    "    def add_file(self, filename):\n",
    "        \"\"\"Adds a file to the text Model\n",
    "        \"\"\"\n",
    "        file = open(filename, 'r')\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        text = clean_text(text)\n",
    "        \n",
    "        self.add_string(text)\n",
    "        \n",
    "            \n",
    "    def save_model(self):\n",
    "        \"\"\"Save model to directory\n",
    "        \"\"\"\n",
    "        filename_words =  self.name + '_' + 'words'\n",
    "        dictionary = self.words\n",
    "        file = open(filename_words, 'w')\n",
    "        file.write(str(dictionary))\n",
    "        file.close\n",
    "\n",
    "        filename_words =  self.name + '_' + 'stems'\n",
    "        dictionary = self.stems\n",
    "        file = open(filename_words, 'w')\n",
    "        file.write(str(dictionary))\n",
    "        file.close\n",
    "\n",
    "        filename_words =  self.name + '_' + 'sentence_lengths'\n",
    "        dictionary = self.sentence_lengths\n",
    "        file = open(filename_words, 'w')\n",
    "        file.write(str(dictionary))\n",
    "        file.close\n",
    "\n",
    "        filename_word_lens = self.name + '_' + 'word_lengths'\n",
    "        dictionary = self.word_lengths\n",
    "        file = open(filename_word_lens, 'w')\n",
    "        file.write(str(dictionary))\n",
    "        file.close\n",
    "\n",
    "        filename_word_lens = self.name + '_' + 'punctuation'\n",
    "        dictionary = self.punc\n",
    "        file = open(filename_word_lens, 'w')\n",
    "        file.write(str(dictionary))\n",
    "        file.close\n",
    "        \n",
    "        \n",
    "\n",
    "    def read_model(self):\n",
    "        \"\"\"Read file from directory\n",
    "        \"\"\"\n",
    "        filename_words =  self.name + '_' + 'words'\n",
    "        file = open(filename_words, 'r')    # Open for reading.\n",
    "        d_str = file.read()           # Read in a string that represents a dict.\n",
    "        file.close()\n",
    "        self.words = dict(eval(d_str))\n",
    "        \n",
    "        filename_words =  self.name + '_' + 'stems'\n",
    "        file = open(filename_words, 'r')    # Open for reading.\n",
    "        d_str = file.read()           # Read in a string that represents a dict.\n",
    "        file.close()\n",
    "        self.words = dict(eval(d_str))\n",
    "\n",
    "        filename_words =  self.name + '_' + 'sentence_lengths'\n",
    "        file = open(filename_words, 'r')    # Open for reading.\n",
    "        d_str = file.read()           # Read in a string that represents a dict.\n",
    "        file.close()\n",
    "        self.words = dict(eval(d_str))\n",
    "\n",
    "        filename_words =  self.name + '_' + 'punctuation'\n",
    "        file = open(filename_words, 'r')    # Open for reading.\n",
    "        d_str = file.read()           # Read in a string that represents a dict.\n",
    "        file.close()\n",
    "        self.words = dict(eval(d_str))\n",
    "\n",
    "        filename_word_lens =  self.name + '_' + 'word_lengths'\n",
    "        file = open(filename_word_lens, 'r')    # Open for reading.\n",
    "        d_str = file.read()           # Read in a string that represents a dict.\n",
    "        file.close()\n",
    "        self.word_lengths = dict(eval(d_str))\n",
    "\n",
    "    def similarity_scores(self, other):\n",
    "        list_scores = []\n",
    "        sim_words = compare_dictionaries(self.words, other.words)\n",
    "        list_scores += [sim_words]\n",
    "        \n",
    "        sim_word_lengths = compare_dictionaries(self.word_lengths, other.word_lengths)\n",
    "        list_scores += [sim_word_lengths]\n",
    "        \n",
    "        sim_stems = compare_dictionaries(self.stems, other.stems)\n",
    "        list_scores += [sim_stems]\n",
    "        \n",
    "        sim_sentence_lengths = compare_dictionaries(self.sentence_lengths, other.sentence_lengths)\n",
    "        list_scores += [sim_sentence_lengths]\n",
    "\n",
    "        sim_punc = compare_dictionaries(self.punc, other.punc)\n",
    "        list_scores += [sim_punc]\n",
    "\n",
    "        return list_scores\n",
    "\n",
    "        \n",
    "    def classify(self, source1, source2):\n",
    "        \"\"\"that compares the called TextModel object (self) to two\n",
    "           other “source” TextModel objects (source1 and source2) \n",
    "           and determines which\n",
    "           of these other TextModels is the more likely source\n",
    "           of the called TextModel.\n",
    "        \"\"\"\n",
    "        scores1 = self.similarity_scores(source1)\n",
    "        scores2 = self.similarity_scores(source2)\n",
    "        scores1 = [ '%.2f' % elem for elem in scores1 ]\n",
    "        scores1 = [elem[1:] for elem in scores1]\n",
    "        for i in range(len(scores1)):\n",
    "            scores1[i] = float(scores1[i])\n",
    "        scores2 = [ '%.2f' % elem for elem in scores2 ]\n",
    "        scores2 = [elem[1:] for elem in scores2]\n",
    "        for i in range(len(scores2)):\n",
    "            scores2[i] = float(scores2[i])\n",
    "        for i in range(len(scores1)):\n",
    "            scores1[i] = -scores1[i]\n",
    "            scores2[i] = -scores2[i]\n",
    "        \n",
    "    \n",
    "        print('Scores for',source1.name, scores1)\n",
    "        print('Scores for',source2.name, scores2)\n",
    "        sum_score1 = 0\n",
    "        sum_score2 = 0\n",
    "        for i in range(len(scores1)):\n",
    "            sum_score1 += scores1[i]\n",
    "            sum_score2 += scores2[i]\n",
    "        sum_score1 = sum_score1/5\n",
    "        sum_score2 = sum_score2/5\n",
    "\n",
    "        if sum_score1 >= sum_score2:\n",
    "            print(self.name,'is more likley to have come from', source1.name)\n",
    "        else:\n",
    "            print(self.name,'is more likley to have come from', source2.name)\n",
    "   # print(\"\\n\")\n",
    "    \n",
    "\n",
    "# at the bottom of the file, *outside* of the TextModel class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests():\n",
    "    \"\"\" runs tests on a series of files to determine wether they are similar \"\"\"\n",
    "    source1 = TextModel('Washington Post')\n",
    "    source1.add_file('WSJ_source_text.txt')\n",
    "\n",
    "    source2 = TextModel('Shakespeare_Romeo')\n",
    "    source2.add_file('shakespeare_source_text.txt')\n",
    "\n",
    "    new1 = TextModel('Personal Writing Sample')\n",
    "    new1.add_file('wr_100_source_text.txt')\n",
    "    new1.classify(source1, source2)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "#three other new models below.\n",
    "\n",
    "    source3 = TextModel('friends_transcript')\n",
    "    source3.add_file('friends_source_text.txt')\n",
    "\n",
    "    source4 = TextModel('New York Times')\n",
    "    source4.add_file('NYT11.txt')\n",
    "    source4.classify(source3, source1)\n",
    "    print(\"\\n\")\n",
    "    #NYT is compared to Friends_transcript and Washington Post\n",
    "\n",
    "    source5 = TextModel('Class_notes')\n",
    "    source5.add_file('Class_notes.txt')\n",
    "    source5.classify(source3, source1)\n",
    "    #Class_notes is compared to friends_transcipt and Washington Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores for', 'Washington Post', [-1281.46, -6.89, -1150.56, -0.69, -0.0])\n",
      "('Scores for', 'Shakespeare_Romeo', [-613.17, -0.0, -502.94, -0.69, -0.0])\n",
      "('Personal Writing Sample', 'is more likley to have come from', 'Shakespeare_Romeo')\n",
      "\n",
      "\n",
      "('Scores for', 'friends_transcript', [-1121.03, -13.27, -1014.9, -0.69, -0.0])\n",
      "('Scores for', 'Washington Post', [-1001.63, -6.63, -882.23, -0.69, -0.0])\n",
      "('New York Times', 'is more likley to have come from', 'Washington Post')\n",
      "\n",
      "\n",
      "('Scores for', 'friends_transcript', [-4111.52, -38.64, -3810.11, -0.69, -4.77])\n",
      "('Scores for', 'Washington Post', [-4065.15, -23.19, -3709.64, -0.69, -0.0])\n",
      "('Class_notes', 'is more likley to have come from', 'Washington Post')\n"
     ]
    }
   ],
   "source": [
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
